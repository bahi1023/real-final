name: $(Date:yyyyMMdd)$(Rev:.r)-ArgoCD
trigger: none
pr: none

variables:
  AWS_SERVICE_CONNECTION: 'bahi-aws-v2'
  AWS_REGION: 'us-east-1'
  # OPTIMIZATION: We assume CLUSTER_NAME is provided as a pipeline variable
  CLUSTER_NAME: 'eks-platform-nonprod-v2-cluster'


# pool:
#   vmImage: ubuntu-latest

pool:
 name: queue-bebo_mohammed

jobs:
- job: ArgoSync
  displayName: 'ArgoCD Sync / Rollout'
  steps:
  - checkout: self

  # 1. Configure Kubeconfig directly using the Variable (No Terraform needed)
  - task: AWSShellScript@1
    displayName: Configure kubeconfig
    inputs:
      awsCredentials: $(AWS_SERVICE_CONNECTION)
      regionName: $(AWS_REGION)
      scriptType: inline
      inlineScript: |
        set -euo pipefail
        
        if [ -z "$(CLUSTER_NAME)" ]; then
          echo "Error: CLUSTER_NAME variable is not set."
          echo "Please set 'CLUSTER_NAME' in your Pipeline Variables (e.g. realfinal-eks)."
          exit 1
        fi

        echo "Checking if cluster $(CLUSTER_NAME) exists..."
        if ! aws eks describe-cluster --name "$(CLUSTER_NAME)" --region "$(AWS_REGION)" >/dev/null 2>&1; then
           echo "##[warning]Cluster $(CLUSTER_NAME) not found. Skipping kubeconfig setup."
           echo "##vso[task.setvariable variable=CLUSTER_EXISTS]false"
           exit 0
        fi

        echo "Connecting to cluster: $(CLUSTER_NAME)..."
        aws eks update-kubeconfig --name "$(CLUSTER_NAME)" --region "$(AWS_REGION)"
        echo "##vso[task.setvariable variable=CLUSTER_EXISTS]true"

  # 1.5. Docker Login (to utilize Service Connection)
  - task: Docker@2
    displayName: Docker Login
    inputs:
      command: login
      containerRegistry: 'docker'  # Uses your "docker" service connection

  # 1.6 Export Docker Credentials to Pipeline Variables (Process similar to AWS)
  - task: Bash@3
    displayName: Export Docker Credentials
    inputs:
      targetType: inline
      script: |
        echo "Exporting Docker credentials to pipeline variables..."
        
        # Read the auth config generated by Docker Login
        # Usually located at ~/.docker/config.json
        DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker}
        CONFIG_FILE="$DOCKER_CONFIG/config.json"
        
        if [ ! -f "$CONFIG_FILE" ]; then
            echo "Error: Docker config file not found at $CONFIG_FILE"
            exit 1
        fi
        
        # Extract auth string (username:password base64 encoded)
        # We use python for reliable JSON parsing since jq might not be available
        AUTH_STRING=$(python3 -c "import json, sys; data = json.load(open('$CONFIG_FILE')); print(list(data['auths'].values())[0]['auth'])")
        
        # Decode base64 to get username:password
        DECODED_AUTH=$(echo "$AUTH_STRING" | base64 -d)
        
        # Split into username and password
        DOCKER_USERNAME=$(echo "$DECODED_AUTH" | cut -d: -f1)
        DOCKER_PASSWORD=$(echo "$DECODED_AUTH" | cut -d: -f2-)
        
        # Export content to pipeline variables using VSO commands (Just like AWS example!)
        echo "##vso[task.setvariable variable=DOCKER_USERNAME;isSecret=false]$DOCKER_USERNAME"
        echo "##vso[task.setvariable variable=DOCKER_PASSWORD;isSecret=true]$DOCKER_PASSWORD"
        
        echo "Successfully exported DOCKER_USERNAME and DOCKER_PASSWORD"

  # 2. Deploy/Update Motivational App
  - task: AWSShellScript@1
    displayName: Deploy Motivational App (Helm)
    inputs:
      awsCredentials: $(AWS_SERVICE_CONNECTION)
      regionName: $(AWS_REGION)
      scriptType: inline
      inlineScript: |
        set -euo pipefail
        
        if [ "$(CLUSTER_EXISTS)" == "false" ]; then
           echo "Cluster does not exist. Skipping deployment."
           exit 0
        fi

        # Use the pipeline variables we just exported!
        echo "Reading Docker credentials from pipeline variables..."
        # Note: They are automatically mapped in env section below
        
        if [ -z "$DOCKER_USERNAME" ] || [ -z "$DOCKER_PASSWORD" ]; then
          echo "ERROR: Docker credentials not found in environment variables"
          exit 1
        fi

        # Create Docker Registry Secret (regcred) in bahi namespace - FORCE UPDATE
        # Delete existing secret to ensure we use the latest credentials
        kubectl delete secret regcred -n bahi --ignore-not-found=true
        
        echo "Creating 'regcred' secret for Docker Registry in bahi namespace..."
        kubectl create secret docker-registry regcred \
          --namespace bahi \
          --docker-server=https://index.docker.io/v1/ \
          --docker-username="$DOCKER_USERNAME" \
          --docker-password="$DOCKER_PASSWORD" \
          --docker-email=bebomohammed904@gmail.com
        
        # Ensure Helm is installed (if not already by previous stages, but good to be safe/consistent)
        if ! command -v helm &> /dev/null; then
            echo "Installing Helm..."
            curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
        fi

        echo "Deploying Helm Chart to bahi namespace..."
        # Using the motivational-app chart we created
        # Injecting the BuildId as the image tag so it pulls the artifacts built in Release Pipeline
        
        if ! helm upgrade --install motivational-app ./motivational-app \
          --namespace bahi --create-namespace \
          --set image.tag="latest" \
          --wait --timeout 10m \
          --debug; then
            echo "Helm upgrade failed. Debugging..."
            kubectl get pods -n bahi -l app.kubernetes.io/instance=motivational-app
            kubectl logs -n bahi -l app.kubernetes.io/instance=motivational-app --tail=50
            exit 1
        fi

        echo "Forcing restart of application deployment to ensure latest image..."
        # Use label selector to dynamically find the deployment created by Helm
        kubectl rollout restart deployment -n bahi -l app.kubernetes.io/instance=motivational-app
        
        echo "Checking rollout status..."
        DEPLOYMENT_NAME=$(kubectl get deployment -n bahi -l app.kubernetes.io/instance=motivational-app -o jsonpath='{.items[0].metadata.name}')
        if [ -n "$DEPLOYMENT_NAME" ]; then
          kubectl rollout status deployment/$DEPLOYMENT_NAME -n bahi
        else
          echo "Warning: Could not find deployment for motivational-app"
        fi




